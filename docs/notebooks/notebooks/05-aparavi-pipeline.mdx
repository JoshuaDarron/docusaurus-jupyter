---
title: Aparavi Pipeline Execution
---

import PipelineResults from "@site/src/components/PipelineResults";
import pipelineConfig from "@site/pipelines/pipeline-config.json";

import pipelineResults from "@site/static/data/pipeline-results.json";

This page demonstrates executing an Aparavi DTC pipeline end-to-end using the
[Aparavi SDK](https://pypi.org/project/aparavi-dtc-sdk/). The pipeline ingests
sample documents from Google Drive, parses them, splits the text into chunks,
and returns the processed documents.

## Pipeline Overview

The pipeline consists of four stages connected in sequence:

1. **Google Drive Source** — Pulls documents from the Hackathon sample dataset
2. **Document Parser** — Extracts text content from raw files
3. **LangChain Chunker** — Splits text using `RecursiveCharacterTextSplitter` with a 512-character window
4. **Response Output** — Collects the processed document chunks

<PipelineResults config={pipelineConfig} results={pipelineResults} />

## Setup Instructions

### 1. Install dependencies

```bash
pip install aparavi-dtc-sdk python-dotenv
```

### 2. Configure credentials

Copy the example environment file and fill in your API key:

```bash
cp .env.example .env
```

Edit `.env` and set your API key (get one from [Aparavi Core](https://core.aparavi.com/usage/)):

```
APARAVI_API_KEY=your-api-key-here
APARAVI_BASE_URL=https://eaas.aparavi.com/
```

### 3. Execute the pipeline

```bash
python scripts/run_pipeline.py
```

This will call the Aparavi API, execute the pipeline workflow, and save the
results to `static/data/pipeline-results.json`. Refresh this page to see the
results displayed above.

## Pipeline Configuration

The pipeline is defined in `pipelines/pipeline-config.json` and was exported
from the Aparavi platform. Key configuration details:

| Parameter | Value |
|-----------|-------|
| Pipeline ID | `7368b3bc-6c8f-4b85-a97d-a9cb73087108` |
| Source | Google Drive — Hackathon dataset |
| Chunk size | 512 characters |
| Splitter | `RecursiveCharacterTextSplitter` |
| Output | Processed document chunks |
