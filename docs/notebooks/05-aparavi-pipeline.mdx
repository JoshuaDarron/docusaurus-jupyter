---
title: Aparavi Pipeline Execution
---

import PipelineResults from "@site/src/components/PipelineResults";
import pipelineConfig from "@site/pipelines/pipeline-config.json";

This page demonstrates executing an Aparavi DTC pipeline end-to-end using the
[Aparavi SDK](https://pypi.org/project/aparavi-dtc-sdk/). The pipeline ingests
sample documents from Google Drive, parses them, splits the text into chunks,
and returns the processed documents.

## Pipeline Overview

The pipeline consists of four stages connected in sequence:

1. **Google Drive Source** — Pulls documents from the Hackathon sample dataset
2. **Document Parser** — Extracts text content from raw files
3. **LangChain Chunker** — Splits text using `RecursiveCharacterTextSplitter` with a 512-character window
4. **Response Output** — Collects the processed document chunks

<PipelineResults config={pipelineConfig} />

## Setup Instructions

### 1. Configure credentials

Copy the example environment file and fill in your API key:

```bash
cp .env.example .env
```

Edit `.env` and set your API key (get one from [Aparavi Core](https://core.aparavi.com/usage/)):

```
APARAVI_API_KEY=your-api-key-here
APARAVI_BASE_URL=https://eaas.aparavi.com/
```

### 2. Start the dev server

```bash
npm start
```

### 3. Execute the pipeline

Click the **Execute Pipeline** button above. The pipeline runs directly against
the Aparavi API (proxied through the dev server to avoid CORS issues) and
displays results in real time.

## Pipeline Configuration

The pipeline is defined in `pipelines/pipeline-config.json` and was exported
from the Aparavi platform. Key configuration details:

| Parameter | Value |
|-----------|-------|
| Pipeline ID | `7368b3bc-6c8f-4b85-a97d-a9cb73087108` |
| Source | Google Drive — Hackathon dataset |
| Chunk size | 512 characters |
| Splitter | `RecursiveCharacterTextSplitter` |
| Output | Processed document chunks |
